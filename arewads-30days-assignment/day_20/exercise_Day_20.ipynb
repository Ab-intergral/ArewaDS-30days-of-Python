{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch the text. Status code: 404\n",
      "The ten most frequent words in 'Romeo and Juliet':\n"
     ]
    }
   ],
   "source": [
    "# Read this url and find the 10 most frequent words. romeo_and_juliet = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "import requests\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Fetch the text from the URL\n",
    "url = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    text = response.text\n",
    "else:\n",
    "    print(\"Failed to fetch the text. Status code:\", response.status_code)\n",
    "    text = \"\"\n",
    "\n",
    "# Clean the text and find the most frequent words\n",
    "def get_most_common_words(text, n=10):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    word_counts = Counter(words)\n",
    "    most_common_words = word_counts.most_common(n)\n",
    "    return most_common_words\n",
    "\n",
    "most_frequent_words = get_most_common_words(text, 10)\n",
    "\n",
    "print(\"The ten most frequent words in 'Romeo and Juliet':\")\n",
    "for word, count in most_frequent_words:\n",
    "    print(f\"{word}: {count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for cat weight (metric units): {'min': 3.0, 'max': 7.5, 'mean': 4.708955223880597, 'median': 4.5, 'std_dev': 1.066533799956462}\n",
      "Statistics for cat lifespan (years): {'min': 10.5, 'max': 19.0, 'mean': 13.746268656716419, 'median': 13.5, 'std_dev': 1.5844249849048053}\n",
      "\n",
      "Frequency table of country and breed:\n",
      "Egypt - Abyssinian: 1 occurrences\n",
      "Greece - Aegean: 1 occurrences\n",
      "United States - American Bobtail: 1 occurrences\n",
      "United States - American Curl: 1 occurrences\n",
      "United States - American Shorthair: 1 occurrences\n",
      "United States - American Wirehair: 1 occurrences\n",
      "United Arab Emirates - Arabian Mau: 1 occurrences\n",
      "Australia - Australian Mist: 1 occurrences\n",
      "United States - Balinese: 1 occurrences\n",
      "United States - Bambino: 1 occurrences\n",
      "United States - Bengal: 1 occurrences\n",
      "France - Birman: 1 occurrences\n",
      "United States - Bombay: 1 occurrences\n",
      "United Kingdom - British Longhair: 1 occurrences\n",
      "United Kingdom - British Shorthair: 1 occurrences\n",
      "Burma - Burmese: 1 occurrences\n",
      "United Kingdom - Burmilla: 1 occurrences\n",
      "United States - California Spangled: 1 occurrences\n",
      "United States - Chantilly-Tiffany: 1 occurrences\n",
      "France - Chartreux: 1 occurrences\n",
      "Egypt - Chausie: 1 occurrences\n",
      "United States - Cheetoh: 1 occurrences\n",
      "United States - Colorpoint Shorthair: 1 occurrences\n",
      "United Kingdom - Cornish Rex: 1 occurrences\n",
      "Canada - Cymric: 1 occurrences\n",
      "Cyprus - Cyprus: 1 occurrences\n",
      "United Kingdom - Devon Rex: 1 occurrences\n",
      "Russia - Donskoy: 1 occurrences\n",
      "China - Dragon Li: 1 occurrences\n",
      "Egypt - Egyptian Mau: 1 occurrences\n",
      "Burma - European Burmese: 1 occurrences\n",
      "United States - Exotic Shorthair: 1 occurrences\n",
      "United Kingdom - Havana Brown: 1 occurrences\n",
      "United States - Himalayan: 1 occurrences\n",
      "Japan - Japanese Bobtail: 1 occurrences\n",
      "United States - Javanese: 1 occurrences\n",
      "Thailand - Khao Manee: 1 occurrences\n",
      "Thailand - Korat: 1 occurrences\n",
      "Russia - Kurilian: 1 occurrences\n",
      "Thailand - LaPerm: 1 occurrences\n",
      "United States - Maine Coon: 1 occurrences\n",
      "United Kingdom - Malayan: 1 occurrences\n",
      "Isle of Man - Manx: 1 occurrences\n",
      "United States - Munchkin: 1 occurrences\n",
      "United States - Nebelung: 1 occurrences\n",
      "Norway - Norwegian Forest Cat: 1 occurrences\n",
      "United States - Ocicat: 1 occurrences\n",
      "United States - Oriental: 1 occurrences\n",
      "Iran (Persia) - Persian: 1 occurrences\n",
      "United States - Pixie-bob: 1 occurrences\n",
      "United States - Ragamuffin: 1 occurrences\n",
      "United States - Ragdoll: 1 occurrences\n",
      "Russia - Russian Blue: 1 occurrences\n",
      "United States - Savannah: 1 occurrences\n",
      "United Kingdom - Scottish Fold: 1 occurrences\n",
      "United States - Selkirk Rex: 1 occurrences\n",
      "Thailand - Siamese: 1 occurrences\n",
      "Russia - Siberian: 1 occurrences\n",
      "Singapore - Singapura: 1 occurrences\n",
      "United States - Snowshoe: 1 occurrences\n",
      "Somalia - Somali: 1 occurrences\n",
      "Canada - Sphynx: 1 occurrences\n",
      "Canada - Tonkinese: 1 occurrences\n",
      "United States - Toyger: 1 occurrences\n",
      "Turkey - Turkish Angora: 1 occurrences\n",
      "Turkey - Turkish Van: 1 occurrences\n",
      "United States - York Chocolate: 1 occurrences\n"
     ]
    }
   ],
   "source": [
    "# Read the cats API and cats_api = 'https://api.thecatapi.com/v1/breeds' and find :\n",
    "# the min, max, mean, median, standard deviation of cats' weight in metric units.\n",
    "# the min, max, mean, median, standard deviation of cats' lifespan in years.\n",
    "# Create a frequency table of country and breed of cats\n",
    "import requests\n",
    "import statistics\n",
    "\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "# Fetch data from the Cat API\n",
    "response = requests.get(cats_api)\n",
    "if response.status_code == 200:\n",
    "    cat_data = response.json()\n",
    "else:\n",
    "    print(\"Failed to fetch cat data. Status code:\", response.status_code)\n",
    "    cat_data = []\n",
    "\n",
    "# Extract weight and lifespan data\n",
    "weights_metric = [cat.get('weight').get('metric') for cat in cat_data if cat.get('weight')]\n",
    "lifespans_years = [cat.get('life_span') for cat in cat_data]\n",
    "\n",
    "# Convert weight strings to numeric values (taking the average if a range is provided)\n",
    "weights_numeric = []\n",
    "for weight in weights_metric:\n",
    "    parts = weight.split('-')\n",
    "    if len(parts) == 1:\n",
    "        weights_numeric.append(float(parts[0]))\n",
    "    else:\n",
    "        weights_numeric.append((float(parts[0]) + float(parts[1])) / 2)\n",
    "\n",
    "# Convert lifespan strings to numeric values (taking the average if a range is provided)\n",
    "lifespans_numeric = []\n",
    "for lifespan in lifespans_years:\n",
    "    parts = lifespan.split('-')\n",
    "    if len(parts) == 1:\n",
    "        lifespans_numeric.append(float(parts[0]))\n",
    "    else:\n",
    "        lifespans_numeric.append((float(parts[0]) + float(parts[1])) / 2)\n",
    "\n",
    "# Calculate statistics\n",
    "weight_stats = {\n",
    "    'min': min(weights_numeric),\n",
    "    'max': max(weights_numeric),\n",
    "    'mean': statistics.mean(weights_numeric),\n",
    "    'median': statistics.median(weights_numeric),\n",
    "    'std_dev': statistics.stdev(weights_numeric)\n",
    "}\n",
    "\n",
    "lifespan_stats = {\n",
    "    'min': min(lifespans_numeric),\n",
    "    'max': max(lifespans_numeric),\n",
    "    'mean': statistics.mean(lifespans_numeric),\n",
    "    'median': statistics.median(lifespans_numeric),\n",
    "    'std_dev': statistics.stdev(lifespans_numeric)\n",
    "}\n",
    "\n",
    "# Create a frequency table of country and breed\n",
    "freq_table = {}\n",
    "for cat in cat_data:\n",
    "    country = cat.get('origin')\n",
    "    breed = cat.get('name')\n",
    "    if country and breed:\n",
    "        key = f\"{country} - {breed}\"\n",
    "        freq_table[key] = freq_table.get(key, 0) + 1\n",
    "\n",
    "# Print results\n",
    "print(\"Statistics for cat weight (metric units):\", weight_stats)\n",
    "print(\"Statistics for cat lifespan (years):\", lifespan_stats)\n",
    "print(\"\\nFrequency table of country and breed:\")\n",
    "for key, value in freq_table.items():\n",
    "    print(f\"{key}: {value} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Largest Countries:\n",
      "Russia: 17098242.0 square kilometers\n",
      "Antarctica: 14000000.0 square kilometers\n",
      "Canada: 9984670.0 square kilometers\n",
      "China: 9706961.0 square kilometers\n",
      "United States: 9372610.0 square kilometers\n",
      "Brazil: 8515767.0 square kilometers\n",
      "Australia: 7692024.0 square kilometers\n",
      "India: 3287590.0 square kilometers\n",
      "Argentina: 2780400.0 square kilometers\n",
      "Kazakhstan: 2724900.0 square kilometers\n",
      "\n",
      "10 Most Spoken Languages:\n",
      "eng: 91 countries\n",
      "fra: 46 countries\n",
      "ara: 25 countries\n",
      "spa: 24 countries\n",
      "por: 10 countries\n",
      "nld: 7 countries\n",
      "rus: 7 countries\n",
      "deu: 5 countries\n",
      "zho: 5 countries\n",
      "tsn: 4 countries\n",
      "\n",
      "Total Number of Languages: 155\n"
     ]
    }
   ],
   "source": [
    "# Read the countries API and find\n",
    "# the 10 largest countries\n",
    "# the 10 most spoken languages\n",
    "# the total number of languages in the countries API\n",
    "import requests\n",
    "\n",
    "# Fetch data from the countries API\n",
    "countries_api = 'https://restcountries.com/v3.1/all'\n",
    "response = requests.get(countries_api)\n",
    "if response.status_code == 200:\n",
    "    countries_data = response.json()\n",
    "else:\n",
    "    print(\"Failed to fetch countries data. Status code:\", response.status_code)\n",
    "    countries_data = []\n",
    "\n",
    "# Extract country sizes and languages\n",
    "country_sizes = {}\n",
    "spoken_languages = []\n",
    "\n",
    "for country in countries_data:\n",
    "    if 'name' in country and 'area' in country:\n",
    "        country_sizes[country['name']['common']] = country['area']\n",
    "\n",
    "    if 'languages' in country:\n",
    "        spoken_languages.extend(country['languages'].keys())\n",
    "\n",
    "# Calculate the 10 largest countries\n",
    "largest_countries = sorted(country_sizes.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Calculate the 10 most spoken languages\n",
    "language_count = {}\n",
    "for language in spoken_languages:\n",
    "    language_count[language] = language_count.get(language, 0) + 1\n",
    "\n",
    "most_spoken_languages = sorted(language_count.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Calculate the total number of languages\n",
    "total_languages = len(set(spoken_languages))\n",
    "\n",
    "# Display results\n",
    "print(\"10 Largest Countries:\")\n",
    "for country, size in largest_countries:\n",
    "    print(f\"{country}: {size} square kilometers\")\n",
    "\n",
    "print(\"\\n10 Most Spoken Languages:\")\n",
    "for language, count in most_spoken_languages:\n",
    "    print(f\"{language}: {count} countries\")\n",
    "\n",
    "print(f\"\\nTotal Number of Languages: {total_languages}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch UCI website. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "# UCI is one of the most common places to get data sets for data science and machine learning. \n",
    "# Read the content of UCL (https://archive.ics.uci.edu/ml/datasets.php). \n",
    "# Without additional libraries it will be difficult, so you may try it with BeautifulSoup4\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # URL of UCI Machine Learning Repository\n",
    "# uci_url = 'https://archive.ics.uci.edu/ml/datasets.php'\n",
    "\n",
    "# # Send an HTTP request to the UCI website\n",
    "# response = requests.get(uci_url)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     # Parse the HTML content using BeautifulSoup\n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#     # Find all dataset titles on the page\n",
    "#     dataset_titles = soup.find_all('p', class_='normal')\n",
    "    \n",
    "#     # Display the titles\n",
    "#     print(\"Dataset Titles:\")\n",
    "#     for title in dataset_titles:\n",
    "#         print(title.text.strip())\n",
    "\n",
    "# else:\n",
    "#     print(\"Failed to fetch UCI website. Status code:\", response.status_code)\n",
    "\n",
    "import requests\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class TitleParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_title = False\n",
    "        self.titles = []\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == 'p' and ('class', 'normal') in attrs:\n",
    "            self.in_title = True\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        if self.in_title:\n",
    "            self.titles.append(data.strip())\n",
    "            self.in_title = False\n",
    "\n",
    "# URL of UCI Machine Learning Repository\n",
    "uci_url = 'https://archive.ics.uci.edu/ml/datasets.php'\n",
    "\n",
    "# Send an HTTP request to the UCI website\n",
    "response = requests.get(uci_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using HTMLParser\n",
    "    parser = TitleParser()\n",
    "    parser.feed(response.text)\n",
    "\n",
    "    # Display the titles\n",
    "    print(\"Dataset Titles:\")\n",
    "    for title in parser.titles:\n",
    "        print(title)\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch UCI website. Status code:\", response.status_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
